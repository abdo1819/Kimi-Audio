# Demo Configuration - No LibriSpeech Required
# Uses only synthetic datasets to avoid download issues

name: "demo_no_librispeech"
description: "Demo experiment using only synthetic datasets"
output_dir: "experiments/results"

# Model configuration
model_backend: "kimia"
model_path: "moonshotai/Kimi-Audio-7B-Instruct"
load_detokenizer: true

# Reasoning conditions to test
conditions:
  - "cot_zero_shot"
  - "latent_silent"

# CoT parameters
cot_chain_lengths: [0, 16]
cot_self_consistency_k: [1]
cot_use_skill_retrieval: false

# Latent parameters
latent_loop_depths: [0, 2]
latent_use_timestep_embeddings: false

# Compute budget
budget_matching: "tokens"
max_total_tokens: 200
max_generation_time: 10.0

# Datasets - ONLY synthetic, no LibriSpeech
datasets:
  - "synthetic_count"
  - "temporal_reasoning"
max_samples_per_dataset: 3
noise_conditions:
  - "clean"

# Evaluation
metrics:
  - "accuracy"
  - "token_efficiency"
  - "latency"
eval_batch_size: 1

# Sampling
temperature: 0.0
top_k: 5
seeds: [42]

# Logging
wandb_project: ""  # Disable W&B to avoid login
wandb_run_name: null
save_predictions: true
save_traces: true
log_level: "INFO"
